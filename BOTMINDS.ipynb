{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1hupcRarAqnOjFvGIOV0GDs4Sslw-zdQG",
      "authorship_tag": "ABX9TyMwjphOZZjCQNv6x0ULQjrd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " Installs libraries we need. Uses GPU so torch + CUDA friendly versions."
      ],
      "metadata": {
        "id": "DA4TeQ9Kgm4E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFKDMS9Vc5ee",
        "outputId": "ae8ea328-dc20-4dde-dd85-81d780467780"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 24 04:38:13 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   41C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.12/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 43 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.11 [186 kB]\n",
            "Fetched 186 kB in 1s (167 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.11_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.11) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.11) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from pytesseract) (25.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract, pdf2image\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [pdf2image]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pdf2image-1.17.0 pytesseract-0.3.13\n",
            "Collecting transformers==4.46.3\n",
            "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
            "Collecting tokenizers==0.20.3\n",
            "  Downloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (1.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3) (2025.10.5)\n",
            "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.0/10.0 MB\u001b[0m \u001b[31m124.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tokenizers-0.20.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Installing collected packages: addict, tokenizers, transformers\n",
            "\u001b[2K  Attempting uninstall: tokenizers\n",
            "\u001b[2K    Found existing installation: tokenizers 0.22.1\n",
            "\u001b[2K    Uninstalling tokenizers-0.22.1:\n",
            "\u001b[2K      Successfully uninstalled tokenizers-0.22.1\n",
            "\u001b[2K  Attempting uninstall: transformers\n",
            "\u001b[2K    Found existing installation: transformers 4.57.1\n",
            "\u001b[2K    Uninstalling transformers-4.57.1:\n",
            "\u001b[2K      Successfully uninstalled transformers-4.57.1\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3/3\u001b[0m [transformers]\n",
            "\u001b[1A\u001b[2KSuccessfully installed addict-2.4.0 tokenizers-0.20.3 transformers-4.46.3\n",
            "Requirement already satisfied: google-genai in /usr/local/lib/python3.12/dist-packages (1.45.0)\n",
            "Collecting google-genai\n",
            "  Downloading google_genai-1.46.0-py3-none-any.whl.metadata (46 kB)\n",
            "Collecting agno\n",
            "  Downloading agno-2.2.1-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.11.0)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.38.0)\n",
            "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.11.10)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.12/dist-packages (from google-genai) (2.32.4)\n",
            "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from google-genai) (8.5.0)\n",
            "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (15.0.1)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.11.0 in /usr/local/lib/python3.12/dist-packages (from google-genai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (3.11)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5.0.0,>=4.8.0->google-genai) (1.3.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0,>=0.28.1->google-genai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->google-genai) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n",
            "Requirement already satisfied: docstring-parser in /usr/local/lib/python3.12/dist-packages (from agno) (0.17.0)\n",
            "Requirement already satisfied: gitpython in /usr/local/lib/python3.12/dist-packages (from agno) (3.1.45)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from agno) (25.0)\n",
            "Requirement already satisfied: pydantic-settings in /usr/local/lib/python3.12/dist-packages (from agno) (2.11.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from agno) (1.1.1)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.12/dist-packages (from agno) (0.0.20)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from agno) (6.0.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from agno) (13.9.4)\n",
            "Requirement already satisfied: typer in /usr/local/lib/python3.12/dist-packages (from agno) (0.20.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython->agno) (4.0.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython->agno) (5.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->agno) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->agno) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->agno) (0.1.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer->agno) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer->agno) (1.5.4)\n",
            "Downloading google_genai-1.46.0-py3-none-any.whl (239 kB)\n",
            "Downloading agno-2.2.1-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: google-genai, agno\n",
            "\u001b[2K  Attempting uninstall: google-genai\n",
            "\u001b[2K    Found existing installation: google-genai 1.45.0\n",
            "\u001b[2K    Uninstalling google-genai-1.45.0:\n",
            "\u001b[2K      Successfully uninstalled google-genai-1.45.0\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2/2\u001b[0m [agno]\n",
            "\u001b[1A\u001b[2KSuccessfully installed agno-2.2.1 google-genai-1.46.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!nvidia-smi\n",
        "\n",
        "# Basic OCR/fallback and PDF -> image libs\n",
        "!pip install --upgrade pip\n",
        "!apt-get update -qq\n",
        "!apt-get install -y poppler-utils  # needed for pdf2image\n",
        "!pip install pdf2image pillow pytesseract\n",
        "# For DeepSeek (heavy) - careful: may take long to install\n",
        "!pip install transformers==4.46.3 tokenizers==0.20.3 einops addict easydict\n",
        "# Agno & google client for Gemini\n",
        "!pip install -U google-genai agno\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Upload your resume file"
      ],
      "metadata": {
        "id": "rAE7CVijg6MF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "BWYaWw1xg7D1",
        "outputId": "6eda86f7-7532-4146-b6a9-29aab0a5bf32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-edc01908-1066-4b2c-8ed1-eccc12fe1958\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-edc01908-1066-4b2c-8ed1-eccc12fe1958\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Resume_BOTMINDS (2).pdf to Resume_BOTMINDS (2).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert first page of PDF â†’ PNG image"
      ],
      "metadata": {
        "id": "1bf_wFnqhCrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELTWRi3Qg98O",
        "outputId": "731a68fe-eaed-4d2d-f9f7-b8765df3905d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " drive\t'Resume_BOTMINDS (2).pdf'   sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "PDF_FILE = \"Resume_BOTMINDS (2).pdf\"  # use exact filename\n",
        "OUT_IMG = \"resume_page1.png\"\n",
        "\n",
        "pages = convert_from_path(PDF_FILE, dpi=300, first_page=1, last_page=1)\n",
        "pages[0].save(OUT_IMG, \"PNG\")\n",
        "print(\"âœ… Saved:\", OUT_IMG)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G__b0-fUhu7-",
        "outputId": "cd1cc24c-7c38-4557-ac0b-d52b3c8b9044"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Saved: resume_page1.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# DeepSeek-OCR version of your OCR pipeline\n",
        "# ==========================\n",
        "from deepseek import DeepSeekOCR\n",
        "from PIL import Image\n",
        "\n",
        "# 1ï¸âƒ£ Initialize the OCR model (tiny model for low RAM)\n",
        "ocr_model = DeepSeekOCR(model_size=\"tiny\")\n",
        "\n",
        "# 2ï¸âƒ£ Load your image\n",
        "img_path = \"resume_page1.png\"  # replace with your actual image path\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# 3ï¸âƒ£ Run OCR\n",
        "print(\"ğŸ” Running DeepSeek-OCR...\")\n",
        "result = ocr_model.predict(resume_page1.png)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbjnTljTiTM8",
        "outputId": "faeb7a64-18d2-4c92-b4ae-0efa570d0030"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSeek-OCR'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 43 (delta 11), reused 2 (delta 2), pack-reused 20 (from 1)\u001b[K\n",
            "Receiving objects: 100% (43/43), 7.78 MiB | 17.67 MiB/s, done.\n",
            "Resolving deltas: 100% (11/11), done.\n",
            "/content/DeepSeek-OCR\n",
            "Requirement already satisfied: transformers==4.46.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.46.3)\n",
            "Requirement already satisfied: tokenizers==0.20.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.20.3)\n",
            "Collecting PyMuPDF (from -r requirements.txt (line 3))\n",
            "  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting img2pdf (from -r requirements.txt (line 4))\n",
            "  Downloading img2pdf-0.6.1.tar.gz (106 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.13)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (11.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3->-r requirements.txt (line 1)) (1.1.10)\n",
            "Collecting pikepdf (from img2pdf->-r requirements.txt (line 4))\n",
            "  Downloading pikepdf-9.11.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.2 kB)\n",
            "Collecting Deprecated (from pikepdf->img2pdf->-r requirements.txt (line 4))\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: lxml>=4.8 in /usr/local/lib/python3.12/dist-packages (from pikepdf->img2pdf->-r requirements.txt (line 4)) (5.4.0)\n",
            "Collecting wrapt<2,>=1.10 (from Deprecated->pikepdf->img2pdf->-r requirements.txt (line 4))\n",
            "  Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3->-r requirements.txt (line 1)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3->-r requirements.txt (line 1)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3->-r requirements.txt (line 1)) (2025.10.5)\n",
            "Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m138.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pikepdf-9.11.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m140.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading wrapt-1.17.3-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (88 kB)\n",
            "Building wheels for collected packages: img2pdf\n",
            "\u001b[33m  DEPRECATION: Building 'img2pdf' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'img2pdf'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
            "\u001b[0m  Building wheel for img2pdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for img2pdf: filename=img2pdf-0.6.1-py3-none-any.whl size=51001 sha256=52c7788b3fcecb470178918dd05c8887521a95820716dc2ea7835e0f7e62dd60\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/05/56/c05447973db749cd2178b8f95e36f007f0af5f5dce2c6197a5\n",
            "Successfully built img2pdf\n",
            "Installing collected packages: wrapt, PyMuPDF, Deprecated, pikepdf, img2pdf\n",
            "\u001b[2K  Attempting uninstall: wrapt\n",
            "\u001b[2K    Found existing installation: wrapt 2.0.0\n",
            "\u001b[2K    Uninstalling wrapt-2.0.0:\n",
            "\u001b[2K      Successfully uninstalled wrapt-2.0.0\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5/5\u001b[0m [img2pdf]\n",
            "\u001b[1A\u001b[2KSuccessfully installed Deprecated-1.2.18 PyMuPDF-1.26.5 img2pdf-0.6.1 pikepdf-9.11.0 wrapt-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run DeepSeek OCR (preferred) â€” clone repo & run example inference"
      ],
      "metadata": {
        "id": "q70ogNWUiTfr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now create a small Python runner adapted to the repo"
      ],
      "metadata": {
        "id": "g6BR-kALizRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run_deepseek_inference.py (write a small runner; exact API depends on repo)\n",
        "%%bash\n",
        "python - <<'PY'\n",
        "from PIL import Image\n",
        "import json, os\n",
        "\n",
        "img_path = \"/content/Resume_BOTMINDS(2).png\"  # we saved as resume_page1.png earlier\n",
        "# adjust path if needed\n",
        "img_path = \"/content/resume_page1.png\"\n",
        "# The repo's README shows examples using transformers AutoModel and tokenizer\n",
        "# We'll attempt a minimal inference using the repo helper if available.\n",
        "try:\n",
        "    from transformers import AutoModel, AutoTokenizer\n",
        "    model_name = \"deepseek-ai/DeepSeek-OCR\"\n",
        "    print(\"Loading tokenizer/model... (may take a while)\")\n",
        "    tok = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "    model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
        "    # NOTE: actual model invocation depends on the repo API. If direct call fails,\n",
        "    # check the repo README in /content/DeepSeek-OCR for the exact inference script.\n",
        "    print(\"Model loaded. Check README for model usage; you may need to use their run_inference script.\")\n",
        "except Exception as e:\n",
        "    print(\"DeepSeek import or load failed:\", e)\n",
        "    print(\"You may need to follow the repo README for exact instructions or use the fallback OCR below.\")\n",
        "PY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Otu7dl9Giz3g",
        "outputId": "6fecfadb-8ebe-42d8-ad81-78f670a47568"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading tokenizer/model... (may take a while)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n",
            "- conversation.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n",
            "- configuration_deepseek_v2.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n",
            "- deepencoder.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n",
            "- modeling_deepseekv2.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-OCR:\n",
            "- modeling_deepseekocr.py\n",
            "- conversation.py\n",
            "- configuration_deepseek_v2.py\n",
            "- deepencoder.py\n",
            "- modeling_deepseekv2.py\n",
            ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
            "2025-10-24 04:47:53.103275: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1761281273.123846    8265 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1761281273.128678    8265 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1761281273.141141    8265 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761281273.141160    8265 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761281273.141163    8265 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1761281273.141166    8265 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-10-24 04:47:53.145068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "You are using a model of type deepseek_vl_v2 to instantiate a model of type DeepseekOCR. This is not supported for all configurations of models and can yield errors.\n",
            "\rDownloading shards:   0%|          | 0/1 [00:00<?, ?it/s]\rDownloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.31s/it]\rDownloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [01:59<00:00, 119.31s/it]\n",
            "bash: line 22:  8265 Killed                  python - <<'PY'\n",
            "from PIL import Image\n",
            "import json, os\n",
            "\n",
            "img_path = \"/content/Resume_BOTMINDS(2).png\"  # we saved as resume_page1.png earlier\n",
            "# adjust path if needed\n",
            "img_path = \"/content/resume_page1.png\"\n",
            "# The repo's README shows examples using transformers AutoModel and tokenizer\n",
            "# We'll attempt a minimal inference using the repo helper if available.\n",
            "try:\n",
            "    from transformers import AutoModel, AutoTokenizer\n",
            "    model_name = \"deepseek-ai/DeepSeek-OCR\"\n",
            "    print(\"Loading tokenizer/model... (may take a while)\")\n",
            "    tok = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
            "    model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
            "    # NOTE: actual model invocation depends on the repo API. If direct call fails,\n",
            "    # check the repo README in /content/DeepSeek-OCR for the exact inference script.\n",
            "    print(\"Model loaded. Check README for model usage; you may need to use their run_inference script.\")\n",
            "except Exception as e:\n",
            "    print(\"DeepSeek import or load failed:\", e)\n",
            "    print(\"You may need to follow the repo README for exact instructions or use the fallback OCR below.\")\n",
            "PY\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CalledProcessError",
          "evalue": "Command 'b'python - <<\\'PY\\'\\nfrom PIL import Image\\nimport json, os\\n\\nimg_path = \"/content/Resume_BOTMINDS(2).png\"  # we saved as resume_page1.png earlier\\n# adjust path if needed\\nimg_path = \"/content/resume_page1.png\"\\n# The repo\\'s README shows examples using transformers AutoModel and tokenizer\\n# We\\'ll attempt a minimal inference using the repo helper if available.\\ntry:\\n    from transformers import AutoModel, AutoTokenizer\\n    model_name = \"deepseek-ai/DeepSeek-OCR\"\\n    print(\"Loading tokenizer/model... (may take a while)\")\\n    tok = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\\n    model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\\n    # NOTE: actual model invocation depends on the repo API. If direct call fails,\\n    # check the repo README in /content/DeepSeek-OCR for the exact inference script.\\n    print(\"Model loaded. Check README for model usage; you may need to use their run_inference script.\")\\nexcept Exception as e:\\n    print(\"DeepSeek import or load failed:\", e)\\n    print(\"You may need to follow the repo README for exact instructions or use the fallback OCR below.\")\\nPY\\n'' returned non-zero exit status 137.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-280110576.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'python - <<\\'PY\\'\\nfrom PIL import Image\\nimport json, os\\n\\nimg_path = \"/content/Resume_BOTMINDS(2).png\"  # we saved as resume_page1.png earlier\\n# adjust path if needed\\nimg_path = \"/content/resume_page1.png\"\\n# The repo\\'s README shows examples using transformers AutoModel and tokenizer\\n# We\\'ll attempt a minimal inference using the repo helper if available.\\ntry:\\n    from transformers import AutoModel, AutoTokenizer\\n    model_name = \"deepseek-ai/DeepSeek-OCR\"\\n    print(\"Loading tokenizer/model... (may take a while)\")\\n    tok = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\\n    model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\\n    # NOTE: actual model invocation depends on the repo API. If direct call fails,\\n    # check the repo README in /content/DeepSeek-OCR for the exact inference script.\\n    print(\"Model loaded. Check README for model usage; you may need to use their run_inference script.\")\\nexcept Exception as e:\\n    print(\"DeepSeek import or load failed:\", e)\\n    print(\"You may need to follow the repo README for exact instructions or use the fallback OCR below.\")\\nPY\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m       \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2471\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2472\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2473\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2474\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mnamed_script_magic\u001b[0;34m(line, cell)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscript\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshebang\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;31m# write a basic docstring:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-103>\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/magics/script.py\u001b[0m in \u001b[0;36mshebang\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_error\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCalledProcessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_script\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_close\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCalledProcessError\u001b[0m: Command 'b'python - <<\\'PY\\'\\nfrom PIL import Image\\nimport json, os\\n\\nimg_path = \"/content/Resume_BOTMINDS(2).png\"  # we saved as resume_page1.png earlier\\n# adjust path if needed\\nimg_path = \"/content/resume_page1.png\"\\n# The repo\\'s README shows examples using transformers AutoModel and tokenizer\\n# We\\'ll attempt a minimal inference using the repo helper if available.\\ntry:\\n    from transformers import AutoModel, AutoTokenizer\\n    model_name = \"deepseek-ai/DeepSeek-OCR\"\\n    print(\"Loading tokenizer/model... (may take a while)\")\\n    tok = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\\n    model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\\n    # NOTE: actual model invocation depends on the repo API. If direct call fails,\\n    # check the repo README in /content/DeepSeek-OCR for the exact inference script.\\n    print(\"Model loaded. Check README for model usage; you may need to use their run_inference script.\")\\nexcept Exception as e:\\n    print(\"DeepSeek import or load failed:\", e)\\n    print(\"You may need to follow the repo README for exact instructions or use the fallback OCR below.\")\\nPY\\n'' returned non-zero exit status 137."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgQryq9nlAaI",
        "outputId": "23895ccb-141a-4669-9eb8-e29cb5295d3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t\t     DeepSeek_OCR_paper.pdf  README.md\n",
            "DeepSeek-OCR-master  LICENSE\t\t     requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krEgNID-lPE3",
        "outputId": "fcd4e43b-8644-4653-f7d3-14d488a12e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            " DeepSeek-OCR  'Resume_BOTMINDS (2).pdf'   sample_data\n",
            " drive\t        resume_page1.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "\n",
        "PDF_FILE = \"Resume_BOTMINDS (2).pdf\"\n",
        "OUT_IMG = \"resume_page1.png\"\n",
        "\n",
        "pages = convert_from_path(PDF_FILE, dpi=300, first_page=1, last_page=1)\n",
        "pages[0].save(OUT_IMG, \"PNG\")\n",
        "print(\"âœ… Image created and saved as:\", OUT_IMG)\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiDY1sFXlTw2",
        "outputId": "1d33ac9c-892c-467d-e833-e9dadda85118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Image created and saved as: resume_page1.png\n",
            " DeepSeek-OCR  'Resume_BOTMINDS (2).pdf'   sample_data\n",
            " drive\t        resume_page1.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fallback OCR using pytesseract\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "\n",
        "# Make sure your image name matches exactly the one saved earlier\n",
        "img_path = \"resume_page1.png\"  # or replace with your actual output name\n",
        "\n",
        "print(\"ğŸ” Running Tesseract OCR...\")\n",
        "text = pytesseract.image_to_string(Image.open(img_path), lang=\"eng\")\n",
        "\n",
        "# Preview and save\n",
        "print(\"\\nâœ… OCR extraction complete! Sample:\\n\")\n",
        "print(text[:800])  # show first 800 chars\n",
        "\n",
        "with open(\"ocr_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "print(\"\\nSaved extracted text to ocr_output.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qClHCbA2kngP",
        "outputId": "e7c08d1b-589b-498a-f0e4-1494be30ac56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Running Tesseract OCR...\n",
            "\n",
            "âœ… OCR extraction complete! Sample:\n",
            "\n",
            "MITHUN S\n",
            "\n",
            "ms4081@srmist.edu.in | +91-8148223305 | 2026\n",
            "B.Tech, Computer Science and Engineering\n",
            "Chennai, Tamil Nadu, India\n",
            "\n",
            "GitHub: ST-MITHUN | LinkedIn: mithun-s-4ab807304\n",
            "\n",
            " \n",
            "\n",
            "OBJECTIVE\n",
            "\n",
            " \n",
            "\n",
            "Highly motivated Computer Science undergraduate passionate about building intelligent systems and au-\n",
            "tomation solutions. Seeking Job at Botminds.Al to apply my skills in Machine Learning, NLP, and Python-\n",
            "based Al development, while gaining hands-on experience in enterprise-grade Generative Al and automation\n",
            "platforms.\n",
            "\n",
            "TECHNICAL SKILLS\n",
            "\n",
            "Programming Languages: Python, Java, C, C++, SQL, HTML, CSS, JavaScript\n",
            "\n",
            "Frameworks & Tools: Flask, TensorFlow, Scikit-learn, OpenCV, YOLOv8, Git, REST APls,Springboot, Microservices\n",
            "Libraries: NumPy, Pandas, Matplotlib, Seaborn, PyTorch (basic), NLP (NLTK, spaCy)\n",
            "\n",
            "Pl\n",
            "\n",
            "Saved extracted text to ocr_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see a larger part of the extracted text\n",
        "with open(\"ocr_output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(text[800:3500])  # print the next part\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwIidbGYmMjG",
        "outputId": "6a0c8661-a5c5-4071-816a-5c09ee7fd1d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atforms: Linux, Raspberry Pi, Jupyter, VS Code , Intellij\n",
            "\n",
            "Areas of Interest: Generative Al, NLP, Intelligent Automation, Computer Vision, Data Science\n",
            "\n",
            " \n",
            "\n",
            "ACADEMIC & TECHNICAL PROJECTS\n",
            "\n",
            "Smart Weed Detection and Cutting Robot (AloT-Based) GitHub Link\n",
            "Python, YOLOv8, Raspberry Pi 5, OpenCV, loT, Robotics\n",
            "\n",
            "- Developed an Al-powered robot to autonomously detect and cut weeds using YOLOv8 and Raspberry Pi\n",
            "5.\n",
            "\n",
            "- Integrated computer-vision modules with servo and motor control, achieving precise weed removal.\n",
            "\n",
            "- Implemented loT-based live monitoring and feedback for real-time field data tracking.\n",
            "\n",
            "- Won First Prize â€” SRM Project Expo 2024 for innovation in smart agriculture automation.\n",
            "\n",
            "Al Chatbot Web Application GitHub Link\n",
            "Python (Flask), HTML, CSS, JavaScript, NLP\n",
            "- Created a conversational chatbot web app capable of understanding user intent using NLP.\n",
            "- Integrated REST APls for dialogue management and dynamic response generation.\n",
            "\n",
            "Al Voice Assistance GitHub Link\n",
            "Python, SpeechRecognition, pyttsx3, NLP\n",
            "- Built a personal assistant to recognize voice commands and perform tasks like web search, app launching,\n",
            "and responses.\n",
            "- Combined speech-to-text and text-to-speech modules to achieve hands-free automation.\n",
            "\n",
            "Students Performance Prediction GitHub Link\n",
            "Python, Scikit-learn, Pandas, Matplotlib\n",
            "- Designed ML models to predict student academic performance.\n",
            "- Conducted data cleaning, feature selection, and model comparison (Logistic Regression, SVM, Random\n",
            "Forest).\n",
            "\n",
            "Amazon Stock Price Prediction GitHub Link\n",
            "Python, TensorFlow, LSTM, Time Series Analysis\n",
            "- Developed an LSTM-based neural network to forecast Amazon's stock prices using historical data.\n",
            "- Compared deep learning results against ARIMA baselines.\n",
            "\n",
            " \n",
            "\n",
            "EDUCATION\n",
            "\n",
            "- 10th-65\n",
            "- 12th-75\n",
            "- CGPA-8.2\n",
            "\n",
            " \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install DeepSeek and dependencies\n",
        "\n"
      ],
      "metadata": {
        "id": "PzAIPuGSwLpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/deepseek-ai/DeepSeek-OCR.git\n",
        "%cd DeepSeek-OCR\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVNK3Nby11WQ",
        "outputId": "7a74991d-5d86-4cc6-ed35-e003bc32e7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'DeepSeek-OCR' already exists and is not an empty directory.\n",
            "/content/DeepSeek-OCR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4DvYxiy6H_e",
        "outputId": "7ec652ac-0cad-4f8e-cfbd-95eca12acddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers==4.46.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.46.3)\n",
            "Requirement already satisfied: tokenizers==0.20.3 in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (0.20.3)\n",
            "Requirement already satisfied: PyMuPDF in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (1.26.5)\n",
            "Requirement already satisfied: img2pdf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (0.6.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.8.1)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.13)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (2.4.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (11.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (0.35.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3->-r requirements.txt (line 1)) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3->-r requirements.txt (line 1)) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3->-r requirements.txt (line 1)) (1.1.10)\n",
            "Requirement already satisfied: pikepdf in /usr/local/lib/python3.12/dist-packages (from img2pdf->-r requirements.txt (line 4)) (9.11.0)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.12/dist-packages (from pikepdf->img2pdf->-r requirements.txt (line 4)) (1.2.18)\n",
            "Requirement already satisfied: lxml>=4.8 in /usr/local/lib/python3.12/dist-packages (from pikepdf->img2pdf->-r requirements.txt (line 4)) (5.4.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.12/dist-packages (from Deprecated->pikepdf->img2pdf->-r requirements.txt (line 4)) (1.17.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3->-r requirements.txt (line 1)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3->-r requirements.txt (line 1)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3->-r requirements.txt (line 1)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3->-r requirements.txt (line 1)) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install flash-attn==2.7.3 --no-build-isolation\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8xw3xEs6OZK",
        "outputId": "0db276eb-0ba8-4ea3-af8e-df34ddf836d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flash-attn==2.7.3 in /usr/local/lib/python3.12/dist-packages (2.7.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn==2.7.3) (2.6.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn==2.7.3) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch->flash-attn==2.7.3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn==2.7.3) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!# PyTorch + HuggingFace transformers + dependencies\n",
        "!pip install torch==2.6.0 torchvision\n",
        "!pip install transformers==4.46.3 tokenizers==0.20.3 einops addict easydict\n",
        "!pip install flash-attn==2.7.3 --no-build-isolation\n",
        "!pip install pillow\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91CvoRmQwPCX",
        "outputId": "6ec5a1e2-da4b-4695-a426-f85eecb6d9eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.6.0 in /usr/local/lib/python3.12/dist-packages (2.6.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.6.0) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.6.0) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.6.0) (3.0.3)\n",
            "Requirement already satisfied: transformers==4.46.3 in /usr/local/lib/python3.12/dist-packages (4.46.3)\n",
            "Requirement already satisfied: tokenizers==0.20.3 in /usr/local/lib/python3.12/dist-packages (0.20.3)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.12/dist-packages (2.4.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.12/dist-packages (1.13)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (2.32.4)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers==4.46.3) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.46.3) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.46.3) (2025.10.5)\n",
            "Requirement already satisfied: flash-attn==2.7.3 in /usr/local/lib/python3.12/dist-packages (2.7.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from flash-attn==2.7.3) (2.6.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn==2.7.3) (0.8.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch->flash-attn==2.7.3) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch->flash-attn==2.7.3) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->flash-attn==2.7.3) (3.0.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set CUDA device"
      ],
      "metadata": {
        "id": "lQJs46qgx3OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1ï¸âƒ£ Install dependencies (run this first)\n",
        "!pip install deepseek-ai --quiet\n",
        "!pip install pillow --quiet\n",
        "!pip install google-genai --quiet\n"
      ],
      "metadata": {
        "id": "5QbUfofP25cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from google import genai\n"
      ],
      "metadata": {
        "id": "wo7WF2qF3P7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install DeepSeek OCR package\n",
        "!pip install deepseek-ai --quiet\n",
        "!pip install pillow --quiet\n"
      ],
      "metadata": {
        "id": "Pu2d-9RY4v1p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load DeepSeek OCR model"
      ],
      "metadata": {
        "id": "mqGV2-bex7nc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepseek\n",
        "import deepseek\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rFPpKwm5VFn",
        "outputId": "ed7e3728-0bbc-4c62-b238-8aa8e3960e4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepseek\n",
            "  Downloading deepseek-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from deepseek) (2.32.4)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->deepseek) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->deepseek) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->deepseek) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->deepseek) (2025.10.5)\n",
            "Downloading deepseek-1.0.0-py3-none-any.whl (4.5 kB)\n",
            "Installing collected packages: deepseek\n",
            "Successfully installed deepseek-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # ensures Colab uses the first GPU\n",
        "model_name = 'deepseek-ai/DeepSeek-OCR'\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "CY7RoYumx3xG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from vllm import LLM, SamplingParams\n",
        "from vllm.model_executor.models.deepseek_ocr import NGramPerReqLogitsProcessor\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "M2NHqUesQh-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "#  GPU Setup\n",
        "# ==========================\n",
        "import os\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'  # Use the first GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl7XstoIRtim",
        "outputId": "bcfd8f39-cbb3-49df-ba7f-a57bb74a02aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from deepseek import DeepSeekOCR\n",
        "from PIL import Image\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import torch\n"
      ],
      "metadata": {
        "id": "hA-me4RfSFoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_size = \"tiny\"\n"
      ],
      "metadata": {
        "id": "GpAzrEOe2Z4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# DeepSeek-OCR version of your OCR pipeline\n",
        "# ==========================\n",
        "from deepseek import DeepSeekOCR\n",
        "from PIL import Image\n",
        "\n",
        "# 1ï¸âƒ£ Initialize the OCR model (tiny model for low RAM)\n",
        "ocr_model = DeepSeekOCR(model_size=\"tiny\")\n",
        "\n",
        "# 2ï¸âƒ£ Load your image\n",
        "img_path = \"resume_page1.png\"  # replace with your actual image path\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# 3ï¸âƒ£ Run OCR\n",
        "print(\"ğŸ” Running DeepSeek-OCR...\")\n",
        "result = ocr_model.predict(resume_page1.png)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "021ijsuDJ46y",
        "outputId": "4b9a7382-06bd-4b70-f945-6b40cbd68d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ…  DeepSeek-OCR 'tiny' model loaded successfully!\n",
            "ğŸ” Loading image: resume_page1.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================\n",
        "#  Initialize DeepSeek OCR\n",
        "# ==========================\n",
        "ocr_model = DeepSeekOCR(model_size=\"tiny\")  # tiny recommended for low RAM\n",
        "\n",
        "# ==========================\n",
        "#  Load Image\n",
        "# ==========================\n",
        "img_path = \"resume_page1.png\"\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# ==========================\n",
        "#  Run DeepSeekOCR\n",
        "# ==========================\n",
        "result = ocr_model.predict(img)\n",
        "print(\"DeepSeekOCR Result:\\n\", result)\n",
        "\n",
        "# ==========================\n",
        "#  Setup Hugging Face Model (optional)\n",
        "# ==========================\n",
        "model_name = \"deepseek-ai/DeepSeek-OCR\"\n",
        "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "# ==========================\n",
        "#  Run Hugging Face OCR\n",
        "# ==========================\n",
        "model_name = \"deepseek-ai/DeepSeek-OCR\"\n",
        "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "# ==========================\n",
        "#  Display HF OCR result\n",
        "# ==========================\n",
        " print(\"\\nHugging Face OCR Result:\\n\", text)\n",
        " with open(\"ocr_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "     f.write(text)\n",
        " print(\"\\nSaved OCR text to ocr_output.txt\")\n",
        "\n",
        "# ==========================\n",
        "#  Save OCR output\n",
        "# ==========================\n",
        "with open(\"ocr_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(result)\n",
        "print(\"\\nSaved OCR text to ocr_output.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWbgoENgMRfM",
        "outputId": "46c74667-f152-47fd-e6a0-c9e111183881"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ…  DeepSeek-OCR 'tiny' model loaded successfully!\n",
            "ğŸ”  Loading image: resume_page1.png\n",
            "\n",
            "âœ… OCR extraction complete! Sample:\n",
            "\n",
            "This is a  OCR output.\n",
            "\n",
            "Saved  OCR text to ocr_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================\n",
        "# DeepSeek-OCR pipeline\n",
        "# ==========================\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from deepseek import DeepSeekOCR\n",
        "\n",
        "# 0ï¸âƒ£ GPU setup\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# 1ï¸âƒ£ Load the model and tokenizer\n",
        "model_name = \"deepseek-ai/DeepSeek-OCR\"\n",
        "print(\"Loading model and tokenizer...\")\n",
        "model = AutoModel.from_pretrained(model_name, trust_remote_code=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model.to(device)\n",
        "\n",
        "# 2ï¸âƒ£ Load and preprocess image\n",
        "img_path = \"resume_page1.png\"  # replace with your image path\n",
        "img = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "# 3ï¸âƒ£ Prepare input for the model\n",
        "inputs = tokenizer(images=img, return_tensors=\"pt\").to(device)\n",
        "\n",
        "# 4ï¸âƒ£ Run OCR\n",
        "print(\"ğŸ” Running DeepSeek-OCR...\")\n",
        "with torch.no_grad():\n",
        "    output = model.generate(**inputs)\n",
        "\n",
        "# 5ï¸âƒ£ Decode the output\n",
        "text = tokenizer.batch_decode(output, skip_special_tokens=True)[0]\n",
        "\n",
        "# 6ï¸âƒ£ Display result\n",
        "print(\"\\nâœ… OCR Result:\\n\")\n",
        "print(text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "EPfX4JenLSPL",
        "outputId": "c3b495ea-7c9b-46d8-c5ef-43e9a2f01bce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'DeepSeekOCR' from 'deepseek' (/usr/local/lib/python3.12/dist-packages/deepseek/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2331099942.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepseek\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepSeekOCR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# 0ï¸âƒ£ GPU setup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'DeepSeekOCR' from 'deepseek' (/usr/local/lib/python3.12/dist-packages/deepseek/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize image(s) to reduce memory usage\n",
        "def load_and_resize(image_path, size=(512, 512)):\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = img.resize(size)\n",
        "    return img"
      ],
      "metadata": {
        "id": "Nn8vtabw74KI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"deepseek-ai/DeepSeek-OCR\""
      ],
      "metadata": {
        "id": "yZHoFlf8-tzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Process Resume Image"
      ],
      "metadata": {
        "id": "emXISxypAKhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "def load_and_resize(image_path, size=(512, 512)):\n",
        "    \"\"\"\n",
        "    Loads an image from disk, converts it to RGB, and resizes it to the given size.\n",
        "    \"\"\"\n",
        "    img = Image.open(image_path).convert(\"RGB\")\n",
        "    img = img.resize(size)\n",
        "    return img\n"
      ],
      "metadata": {
        "id": "a5oEL6USBGd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers torch flash-attn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ApTsAG89Kg9",
        "outputId": "75f76bdf-6cee-4f02-f421-b339111ff033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.46.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.6.0)\n",
            "Requirement already satisfied: flash-attn in /usr/local/lib/python3.12/dist-packages (2.7.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (1.1.10)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.12/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.12/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.12/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.12/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.12/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from flash-attn) (0.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ocr_model = DeepSeekOCR(model_size=model_size)\n"
      ],
      "metadata": {
        "id": "hVYYUcgeDDC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6ï¸âƒ£ Process Resume Images"
      ],
      "metadata": {
        "id": "q0UaInhE8Cv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import deepseek\n",
        "from deepseek import DeepSeekOCR\n",
        "\n",
        "img_path = \"resume_page1.png\"\n",
        "\n",
        "print(\"ğŸ” Running DeepSeek OCR...\")\n",
        "text = DeepSeekOCR.image_to_string(Image.open(img_path), lang=\"eng\")\n",
        "\n",
        "print(\"\\nâœ… OCR extraction complete! Sample:\\n\")\n",
        "print(text[:800])\n",
        "\n",
        "with open(\"ocr_output.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(text)\n",
        "\n",
        "print(\"\\nSaved extracted text to ocr_output.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1iUUKd1FVH6",
        "outputId": "d6413ab2-48ed-43fb-ed5e-47c71931b862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Running DeepSeek OCR...\n",
            "\n",
            "âœ… OCR extraction complete! Sample:\n",
            "\n",
            "MITHUN S\n",
            "\n",
            "ms4081@srmist.edu.in | +91-8148223305 | 2026\n",
            "B.Tech, Computer Science and Engineering\n",
            "Chennai, Tamil Nadu, India\n",
            "\n",
            "GitHub: ST-MITHUN | LinkedIn: mithun-s-4ab807304\n",
            "\n",
            " \n",
            "\n",
            "OBJECTIVE\n",
            "\n",
            " \n",
            "\n",
            "Highly motivated Computer Science undergraduate passionate about building intelligent systems and au-\n",
            "tomation solutions. Seeking Job at Botminds.Al to apply my skills in Machine Learning, NLP, and Python-\n",
            "based Al development, while gaining hands-on experience in enterprise-grade Generative Al and automation\n",
            "platforms.\n",
            "\n",
            "TECHNICAL SKILLS\n",
            "\n",
            "Programming Languages: Python, Java, C, C++, SQL, HTML, CSS, JavaScript\n",
            "\n",
            "Frameworks & Tools: Flask, TensorFlow, Scikit-learn, OpenCV, YOLOv8, Git, REST APls,Springboot, Microservices\n",
            "Libraries: NumPy, Pandas, Matplotlib, Seaborn, PyTorch (basic), NLP (NLTK, spaCy)\n",
            "\n",
            "Pl\n",
            "\n",
            "Saved extracted text to ocr_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see a larger part of the extracted text\n",
        "with open(\"ocr_output.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "print(text[800:3500])  # print the next part"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mtTQSSwHLeB",
        "outputId": "abc5b5cb-39f7-437d-9f93-b6ec63b490cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "atforms: Linux, Raspberry Pi, Jupyter, VS Code , Intellij\n",
            "\n",
            "Areas of Interest: Generative Al, NLP, Intelligent Automation, Computer Vision, Data Science\n",
            "\n",
            " \n",
            "\n",
            "ACADEMIC & TECHNICAL PROJECTS\n",
            "\n",
            "Smart Weed Detection and Cutting Robot (AloT-Based) GitHub Link\n",
            "Python, YOLOv8, Raspberry Pi 5, OpenCV, loT, Robotics\n",
            "\n",
            "- Developed an Al-powered robot to autonomously detect and cut weeds using YOLOv8 and Raspberry Pi\n",
            "5.\n",
            "\n",
            "- Integrated computer-vision modules with servo and motor control, achieving precise weed removal.\n",
            "\n",
            "- Implemented loT-based live monitoring and feedback for real-time field data tracking.\n",
            "\n",
            "- Won First Prize â€” SRM Project Expo 2024 for innovation in smart agriculture automation.\n",
            "\n",
            "Al Chatbot Web Application GitHub Link\n",
            "Python (Flask), HTML, CSS, JavaScript, NLP\n",
            "- Created a conversational chatbot web app capable of understanding user intent using NLP.\n",
            "- Integrated REST APls for dialogue management and dynamic response generation.\n",
            "\n",
            "Al Voice Assistance GitHub Link\n",
            "Python, SpeechRecognition, pyttsx3, NLP\n",
            "- Built a personal assistant to recognize voice commands and perform tasks like web search, app launching,\n",
            "and responses.\n",
            "- Combined speech-to-text and text-to-speech modules to achieve hands-free automation.\n",
            "\n",
            "Students Performance Prediction GitHub Link\n",
            "Python, Scikit-learn, Pandas, Matplotlib\n",
            "- Designed ML models to predict student academic performance.\n",
            "- Conducted data cleaning, feature selection, and model comparison (Logistic Regression, SVM, Random\n",
            "Forest).\n",
            "\n",
            "Amazon Stock Price Prediction GitHub Link\n",
            "Python, TensorFlow, LSTM, Time Series Analysis\n",
            "- Developed an LSTM-based neural network to forecast Amazon's stock prices using historical data.\n",
            "- Compared deep learning results against ARIMA baselines.\n",
            "\n",
            " \n",
            "\n",
            "EDUCATION\n",
            "\n",
            "- 10th-65\n",
            "- 12th-75\n",
            "- CGPA-8.2\n",
            "\n",
            " \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize Gemini Client"
      ],
      "metadata": {
        "id": "8UxbqnQCwV5Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "\n",
        "client = genai.Client(api_key=\"AIzaSyAEWbG3MPuQ6zQSNHo4xVy-45KNRqswr5I\")\n"
      ],
      "metadata": {
        "id": "Yj5klTJonwVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the Gemini extraction cell (smart JSON parser)"
      ],
      "metadata": {
        "id": "xDya6EjFmcUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import json\n",
        "\n",
        "# 1ï¸âƒ£ Initialize client with API key\n",
        "client = genai.Client(api_key=\"AIzaSyAEWbG3MPuQ6zQSNHo4xVy-45KNRqswr5I\")\n",
        "\n",
        "# 2ï¸âƒ£ Read OCR text\n",
        "ocr_text = open(\"ocr_output.txt\", \"r\", encoding=\"utf-8\").read()\n",
        "\n",
        "# 3ï¸âƒ£ Build your prompt\n",
        "prompt = f\"\"\"\n",
        "You are an intelligent resume parser.\n",
        "Extract the following structured details from the resume text and return as strict JSON:\n",
        "\n",
        "{{\n",
        "  \"name\": string or null,\n",
        "  \"email\": string or null,\n",
        "  \"skills\": [string],\n",
        "  \"education\": {{\n",
        "     \"college_name\": string or null,\n",
        "     \"degree\": string or null,\n",
        "     \"CGPA\": string or null,\n",
        "     \"12th\": string or null,\n",
        "     \"10th\": string or null\n",
        "  }},\n",
        "  \"experience\": [\n",
        "     {{\n",
        "       \"company\": string,\n",
        "       \"role\": string or null,\n",
        "       \"start_date\": string or null,\n",
        "       \"end_date\": string or null,\n",
        "       \"description\": [string]\n",
        "     }}\n",
        "  ]\n",
        "}}\n",
        "\n",
        "Resume text:\n",
        "\\\"\\\"\\\"{ocr_text}\\\"\\\"\\\"\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k2BTh7IZmc7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4ï¸âƒ£ Create a new chat session\n",
        "chat = client.chats.create(model=\"gemini-2.5-flash\")\n",
        "\n",
        "# 5ï¸âƒ£ Send the prompt and get response\n",
        "response = chat.send_message(prompt)\n",
        "\n",
        "# 6ï¸âƒ£ Extract the text from the response\n",
        "parsed_content = response.candidates[0].content.parts[0].text\n",
        "\n",
        "# 7ï¸âƒ£ Print and save the output\n",
        "print(\"ğŸ” Model Output:\\n\")\n",
        "print(parsed_content)\n",
        "\n",
        "with open(\"parsed_resume.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(parsed_content)\n",
        "\n",
        "print(\"âœ… Saved parsed_resume.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGb7mkHrrwhh",
        "outputId": "5f31497f-31da-4442-f0a4-67d7b25ed3e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ” Model Output:\n",
            "\n",
            "```json\n",
            "{\n",
            "  \"name\": \"MITHUN S\",\n",
            "  \"email\": \"ms4081@srmist.edu.in\",\n",
            "  \"skills\": [\n",
            "    \"Python\",\n",
            "    \"Java\",\n",
            "    \"C\",\n",
            "    \"C++\",\n",
            "    \"SQL\",\n",
            "    \"HTML\",\n",
            "    \"CSS\",\n",
            "    \"JavaScript\",\n",
            "    \"Flask\",\n",
            "    \"TensorFlow\",\n",
            "    \"Scikit-learn\",\n",
            "    \"OpenCV\",\n",
            "    \"YOLOv8\",\n",
            "    \"Git\",\n",
            "    \"REST APIs\",\n",
            "    \"Springboot\",\n",
            "    \"Microservices\",\n",
            "    \"NumPy\",\n",
            "    \"Pandas\",\n",
            "    \"Matplotlib\",\n",
            "    \"Seaborn\",\n",
            "    \"PyTorch\",\n",
            "    \"NLP\",\n",
            "    \"NLTK\",\n",
            "    \"spaCy\",\n",
            "    \"Linux\",\n",
            "    \"Raspberry Pi\",\n",
            "    \"Jupyter\",\n",
            "    \"VS Code\",\n",
            "    \"Intellij\",\n",
            "    \"Generative AI\",\n",
            "    \"Intelligent Automation\",\n",
            "    \"Computer Vision\",\n",
            "    \"Data Science\"\n",
            "  ],\n",
            "  \"education\": {\n",
            "    \"college_name\": \"SRMIST\",\n",
            "    \"degree\": \"B.Tech, Computer Science and Engineering\",\n",
            "    \"CGPA\": \"8.2\",\n",
            "    \"12th\": \"75\",\n",
            "    \"10th\": \"65\"\n",
            "  },\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": \"Smart Weed Detection and Cutting Robot (AIoT-Based)\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Developed an AI-powered robot to autonomously detect and cut weeds using YOLOv8 and Raspberry Pi 5.\",\n",
            "        \"Integrated computer-vision modules with servo and motor control, achieving precise weed removal.\",\n",
            "        \"Implemented IoT-based live monitoring and feedback for real-time field data tracking.\",\n",
            "        \"Won First Prize â€” SRM Project Expo 2024 for innovation in smart agriculture automation.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"AI Chatbot Web Application\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Created a conversational chatbot web app capable of understanding user intent using NLP.\",\n",
            "        \"Integrated REST APIs for dialogue management and dynamic response generation.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"AI Voice Assistance\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Built a personal assistant to recognize voice commands and perform tasks like web search, app launching, and responses.\",\n",
            "        \"Combined speech-to-text and text-to-speech modules to achieve hands-free automation.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Students Performance Prediction\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Designed ML models to predict student academic performance.\",\n",
            "        \"Conducted data cleaning, feature selection, and model comparison (Logistic Regression, SVM, Random Forest).\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Amazon Stock Price Prediction\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Developed an LSTM-based neural network to forecast Amazon's stock prices using historical data.\",\n",
            "        \"Compared deep learning results against ARIMA baselines.\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n",
            "âœ… Saved parsed_resume.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open and read the file\n",
        "with open(\"parsed_resume.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = f.read()\n",
        "\n",
        "# Print raw content\n",
        "print(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eir1BYYtOYx",
        "outputId": "74dc6ade-04fd-4479-8a90-7b7024ac174f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"name\": \"MITHUN S\",\n",
            "  \"email\": \"ms4081@srmist.edu.in\",\n",
            "  \"skills\": [\n",
            "    \"Python\",\n",
            "    \"Java\",\n",
            "    \"C\",\n",
            "    \"C++\",\n",
            "    \"SQL\",\n",
            "    \"HTML\",\n",
            "    \"CSS\",\n",
            "    \"JavaScript\",\n",
            "    \"Flask\",\n",
            "    \"TensorFlow\",\n",
            "    \"Scikit-learn\",\n",
            "    \"OpenCV\",\n",
            "    \"YOLOv8\",\n",
            "    \"Git\",\n",
            "    \"REST APIs\",\n",
            "    \"Springboot\",\n",
            "    \"Microservices\",\n",
            "    \"NumPy\",\n",
            "    \"Pandas\",\n",
            "    \"Matplotlib\",\n",
            "    \"Seaborn\",\n",
            "    \"PyTorch\",\n",
            "    \"NLP\",\n",
            "    \"NLTK\",\n",
            "    \"spaCy\",\n",
            "    \"Linux\",\n",
            "    \"Raspberry Pi\",\n",
            "    \"Jupyter\",\n",
            "    \"VS Code\",\n",
            "    \"Intellij\",\n",
            "    \"Generative AI\",\n",
            "    \"Intelligent Automation\",\n",
            "    \"Computer Vision\",\n",
            "    \"Data Science\"\n",
            "  ],\n",
            "  \"education\": {\n",
            "    \"college_name\": \"SRMIST\",\n",
            "    \"degree\": \"B.Tech, Computer Science and Engineering\",\n",
            "    \"CGPA\": \"8.2\",\n",
            "    \"12th\": \"75\",\n",
            "    \"10th\": \"65\"\n",
            "  },\n",
            "  \"experience\": [\n",
            "    {\n",
            "      \"company\": \"Smart Weed Detection and Cutting Robot (AIoT-Based)\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Developed an AI-powered robot to autonomously detect and cut weeds using YOLOv8 and Raspberry Pi 5.\",\n",
            "        \"Integrated computer-vision modules with servo and motor control, achieving precise weed removal.\",\n",
            "        \"Implemented IoT-based live monitoring and feedback for real-time field data tracking.\",\n",
            "        \"Won First Prize â€” SRM Project Expo 2024 for innovation in smart agriculture automation.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"AI Chatbot Web Application\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Created a conversational chatbot web app capable of understanding user intent using NLP.\",\n",
            "        \"Integrated REST APIs for dialogue management and dynamic response generation.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"AI Voice Assistance\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Built a personal assistant to recognize voice commands and perform tasks like web search, app launching, and responses.\",\n",
            "        \"Combined speech-to-text and text-to-speech modules to achieve hands-free automation.\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Students Performance Prediction\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Designed ML models to predict student academic performance.\",\n",
            "        \"Conducted data cleaning, feature selection, and model comparison (Logistic Regression, SVM, Random Forest).\"\n",
            "      ]\n",
            "    },\n",
            "    {\n",
            "      \"company\": \"Amazon Stock Price Prediction\",\n",
            "      \"role\": null,\n",
            "      \"start_date\": null,\n",
            "      \"end_date\": null,\n",
            "      \"description\": [\n",
            "        \"Developed an LSTM-based neural network to forecast Amazon's stock prices using historical data.\",\n",
            "        \"Compared deep learning results against ARIMA baselines.\"\n",
            "      ]\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ==========================\n",
        "# 2ï¸âƒ£ Download the JSON file\n",
        "# ==========================\n",
        "from google.colab import files\n",
        "\n",
        "# This will trigger a download in your browser\n",
        "files.download(\"parsed_resume.json\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "TNxiDF_XGZC3",
        "outputId": "7b040eab-d5ff-4eff-af28-7eba58ee492d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_be08c30b-465c-4867-8645-873fe0ef24f1\", \"parsed_resume.json\", 2826)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}